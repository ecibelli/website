---
#date: "2019-03-29"
title:  
---

From 2009-2018, I was a researcher in linguistics, specializing in:

+ **phonetics** (the study of the perception and production of speech sounds),
+ **psycholinguistics** (the study of real-time language processing, and how language and cognition affect one another), and
+ **neurolinguistics** (the study of the structure and function of the brain as it affects language).

This page is an overview of some of my  projects during that time. You can find a full list of my published work <a href = "https://scholar.google.com/citations?user=4vfpQcMAAAAJ&hl=en">here</a>. A handful of these projects have example code <a href = "https://github.com/ecibelli?tab=repositories">hosted on GitHub</a>.

-----

**Speech biomarkers of mental illness**

*Collaborators*: <a href="http://www.psychology.northwestern.edu/people/faculty/core/profiles/vijay-mittal.html">Vijay Mittal</a>, <a href="http://faculty.wcas.northwestern.edu/matt-goldrick/">Matt Goldrick</a>, <a href="http://u.cs.biu.ac.il/~jkeshet/">Joseph Keshet</a>

Can speech be used as a diagnostic tool in clinical psychology? Psychotic disorders like schizophrenia impact motor control, affecting posture and head and limb movement. There's also some evidence for motor/motion disruptions in young adults who are at *risk* for these disorders, but haven't yet been diagnosed. Because speaking depends on a high degree of motor control, it's plausible that these motor disruptions also impact speech. If so, the voice may represent an early warning, non-invasive tool to detect psychosis risk in young adults.

<font size = 2>

+ <a href = "papers/sichlingerCibelliGoldrickMittal.pdf">Sichlinger, L., Cibelli, E., Goldrick, M., & Mittal, V. A. (2019). Clinical correlates of aberrant conversational turn-taking in youth at clinical high-risk for psychosis. *Schizophrenia Research*, 204, 419.</a> 
+ Vargas, T., Osborne, K. J., Cibelli, E. S., & Mittal, V. A. (2019). Separating hearing sensitivity from auditory perceptual abnormalities in clinical high risk (CHR) youth. *Schizophrenia Research*, 204, 437-438.
+ <a href= "https://projectreporter.nih.gov/project_info_description.cfm?aid=9746454&icde=44549007"> NIH 1R21MH119677-01A1</a>

</font>

----

**Acquiring speech sounds in a new language**


Your native language(s) has a big impact on how you perceive and pronounce speech sounds. In some cases, this can make it hard to acquire sounds in a new language, especially if you start learning as an adult. In my dissertation, I explored some different ways to teach adult learners challenging sounds in a new language, focusing both on auditory training (helping you hear the differences between new sounds) and articulatory training (helping you position your tongue, lips, and larynx to pronounce them).

<font size = 2>

+ <a href = "papers/cibelli_phonetica2019.pdf"> Cibelli, E. (2019). Training Non-Native Consonant Production with Perceptual and Articulatory Cues. Phonetica, 1-28.</a> 
+ <a href="papers/cibelli_dissertation.pdf">Find all the gory details in my dissertation.</a>

</font>

----

**Automatic detection of cognitive difficulty**

<i>Collaborators</i>: <a href="http://faculty.wcas.northwestern.edu/matt-goldrick/">Matt Goldrick</a>, <a href="https://pennstate.pure.elsevier.com/en/persons/rhonda-mudry">Rhonda (McClain) Mudry</a>, <a href="http://u.cs.biu.ac.il/~jkeshet/">Joseph Keshet</a>, <a href="http://adiyoss.github.io/">Yossi Adi</a> 

Do cognitive challenges (e.g. speaking a second language, being an older speaker) leave detectible signs in speech? This project attempts to answer this by developing and using <a href = "https://github.com/MLSpeech/DeepPhoneticToolsTutorial">automatic processing algorithms</a> to detect subtle variations in speech. These subtle hints in pronunciation  may indicate that a speaker has a more demanding cognitive task than usual in finding the right word or putting a sentence together.

<font size = 2>

+ <a href = "papers/lexicalSelectionInteraction.pdf">Goldrick, M., McClain, R., Cibelli, E., Adi, Y., Gustafson, E., Moers, C., & Keshet, J. (2018). The influence of lexical selection disruptions on articulation. *Journal of Experimental Psychology: Learning, Memory, and Cognition,* 45(6), 1107â€“1141.</a>
+ <a href="https://arxiv.org/pdf/1610.07918.pdf">Adi, Y., Keshet, J., Cibelli, E., & Goldrick, M. (2017, March). Sequence segmentation using joint RNN and structured prediction models. In  the <i>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i> (pp. 2422-2426). IEEE.</a>
+ <a href="https://pdfs.semanticscholar.org/30ae/51e58bfb6998849caa5e6059b6970bb73062.pdf">Adi, Y., Keshet, J., Cibelli, E., Gustafson, E., Clopper, C., & Goldrick, M. (2016). Automatic measurement of vowel duration via structured prediction. <i>The Journal of the Acoustical Society of America</i> 140 (6), 4517-4527.</a>

</font>

-----

**Color perception and categorization**

<i>Collaborators:</i> <a href="http://lclab.berkeley.edu/regier/">Terry Regier</a>,
<a href="http://www.cs.toronto.edu/~yangxu/">Yang Xu</a>, <a href="https://alab.psych.wisc.edu/">Joe Austerweil</a>, <a href="http://cocosci.berkeley.edu/tom/">Tom Griffiths</a>

How accurate is your perception and memory of physical stimuli? When it comes to color perception, your experience is sometimes (but not always!) affected by the language you speak. Our work in this domain suggests that you are most influenced by the categories in by your native language ("basic" color words like red, blue, and green) when cognitive demands are high. In those circumstances, we see speakers of different languages recalling and classifying the same color in different ways. 

<font size = "2"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0158725">Cibelli, E., Xu, Y., Austerweil, J. L., Griffiths, T. L., & Regier, T. (2016). The Sapir-Whorf Hypothesis and Probabilistic Inference: Evidence from the Domain of Color. *PloS One*, 11(7), e0158725.</a>
<br>(*Co-first authors.)</font>

-----

**The neural pathways of word recognition**

*Collaborators:* <a href ="http://linguistics.berkeley.edu/~kjohnson">Keith Johnson</a>, <a href ="http://changlab.ucsf.edu/edward-chang/">Eddie Chang</a>, <a href="http://profiles.ucsf.edu/matthew.leonard">Matt Leonard</a>

Measuring neural activity during language processing is a challenge - in part because it happens so quickly and across wide networks of the brain. A technique called electocorticography (ECoG) allows a rare look into the simultaneous spatial and temporal dimensions of language processing. We used this approach to look at the neural pathways used to process real words and word-like nonsense forms (e.g. "tesolivy", "piteretion") millisecond by millisecond, and millimeter by millimeter. 

<font size = 2>
<a href="papers/brainLx_cibelli2015.pdf">Cibelli, E.S., Leonard, M.K., Johnson, K., & Chang, E.F. (2015). The influence of lexical statistics on temporal lobe cortical dynamics during spoken word listening. Brain and Language 147, 66-75.</a>
</font>

-----

**Speech and aging**

*Collaborators:* <a href="http://linguistics.berkeley.edu/~gahl">Susanne Gahl</a>, 
<a href="http://www.linguistics.northwestern.edu/people/current-graduate-students/">Kat Hall</a>, 
<a href="http://linguistics.berkeley.edu/person/98">Ronald Sprouse</a></i>

We know that the voice changes throughout childhood, and again late in life. But what happens during the longest span of life - early and middle adulthood? This question is a challenge to study, because it's rare to have recordings of a person's voice over many decades. To tackle this challenge, we measured speech from the Up! movies - a documentary series that has followed the same group of people every seven years of their lives. This corpus is freely available for language and speech researchers to use.

<font size="2">
<a href="http://www.linguistics.berkeley.edu/~gahl/upRev.pdf"> Gahl, S., Cibelli, E., Hall, K., and Sprouse, R. (2014). The "Up" corpus: A corpus of speech samples across adulthood. <i>Corpus Linguistics and Linguistic Theory</i> 10(2), 315-328.</a>
</font>
